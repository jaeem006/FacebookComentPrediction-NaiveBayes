{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Facebook Coment Volume Prediction using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#importamos las bibliotecas necesarias para el proyecto\n",
    "import csv\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que tenemos que hacer es cargar el dataset que esta en un archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcion para cargar un archivo csv por lineas\n",
    "def cargaCsv(file):\n",
    "    lineas = csv.reader(open(file, \"rb\"))\n",
    "    dataset = list(lineas)\n",
    "    for i in range(len(dataset)):\n",
    "        dataset[i] = [float(x) for x in dataset[i]]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dividir los datos contenidos en el csv en datos de train (para entenar) y datos de test (para probar). Esto lo hacemos con un radio definido por nosotros, en este proyecto usaremos 0.7 valor al que llegamos a travez de experimentación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcion para separar los datos en datos de entrenamiento y de test\n",
    "def dividirDatos(dataset, radio):\n",
    "    trainSize = int(len(dataset) * radio)\n",
    "    c = list(dataset)\n",
    "    trainSet = []\n",
    "    while len(trainSet) < trainSize:\n",
    "        index = random.randrange(len(c))\n",
    "        trainSet.append(c.pop(index))\n",
    "    return [trainSet, c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora separaremos los datos de entrenamiento por Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcion que separa los datos de entrenamiento por clases\n",
    "def separarClass(dataset):\n",
    "    otros = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        if (vector[-1] not in otros):\n",
    "            otros[vector[-1]] = []\n",
    "        otros[vector[-1]].append(vector)\n",
    "    return otros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será necesario también calcular la desviación estandar para esto necesitamos calcular la media de cada uno de los atributos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcion que calcula la media\n",
    "def media(numb):\n",
    "    return sum(numb)/float(len(numb))\n",
    "\n",
    "#funcion que calcula la desviacion estandar\n",
    "def desvStdr(numb):\n",
    "    promedio = media(numb)\n",
    "    varianza = sum([pow(x-promedio,2) for x in numb])/float(len(numb))\n",
    "    return math.sqrt(varianza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto ya podemos resumir los datos calculando la desviación estandar y la media de cada uno de los atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resumir(dataset):\n",
    "    res = [(media(atr), desvStdr(atr)) for atr in zip(*dataset)]\n",
    "    del res[-1]\n",
    "    return res\n",
    "\n",
    "def resumenClass(dataset):\n",
    "    res = {}\n",
    "    otros = separarClass(dataset)\n",
    "    for valor, instancia in otros.iteritems():\n",
    "        res[valor] = resumir(instancia)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con todo lo anterior ya podemos comenzar a hacer predicciones, lo primero que haremos será calcular la probabilidad Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcion que calcula la probabilidad Gaussiana\n",
    "def proba(x, media, des):\n",
    "    expo = math.exp(-(math.pow(x-media,2)/(2*math.pow(des,2))))\n",
    "    return (1 / (math.sqrt(2*math.pi) * des)) *\texpo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora combinamos las probabildades de cada uno de los atributos para calcular la probabilidad de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcion para calcular la probabilidad de una clase\n",
    "def classProba(res, vector):\n",
    "    prob = {}\n",
    "    for valor, res in res.iteritems():\n",
    "        prob[valor] = 1\n",
    "        for i in range(len(res)):\n",
    "            media, des = res[i]\n",
    "            x = vector[i]\n",
    "            prob[valor] *= proba(x, media, des)\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los calculos de las probabilidades ya podemos comenzar a hacer predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcion para hacer predicciones\n",
    "def predecir(res, vector):\n",
    "    prob = classProba(res, vector)\n",
    "    etiqueta, mejor = None, -1\n",
    "    for classValue, probability in prob.iteritems():\n",
    "        if etiqueta is None or probability > mejor:\n",
    "            mejor = probability\n",
    "            etiqueta = classValue\n",
    "    return etiqueta\n",
    "\n",
    "#funcion para hacer predicciones para cada una de las instancias de los datos\n",
    "def getPredicciones(res, conj):\n",
    "    predicciones = []\n",
    "    for i in range(len(conj)):\n",
    "        ret = predecir(res, conj[i])\n",
    "        predicciones.append(ret)\n",
    "    return predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente vamos a calcular la precisión de predicción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcion para calcular la precisión\n",
    "def Accuracy(conj, predicciones):\n",
    "    correct = 0\n",
    "    for x in range(len(conj)):\n",
    "        if conj[x][-1] == predicciones[x]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(conj))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#funcion main\n",
    "def main():\n",
    "    dataset = cargaCsv('Dataset/Testing/Features_TestSet.csv')\n",
    "    trainingSet, testSet = dividirDatos(dataset, 0.7)\n",
    "    print('Cargados {0} train={1} test={2}').format(len(dataset), len(trainingSet), len(testSet))\n",
    "    resu = resumenClass(trainingSet)\n",
    "    print('Resumen: {0}%').format(resu)\n",
    "    predicciones = getPredicciones(resu, testSet)\n",
    "    print('predicciones: {0}').format(predicciones)\n",
    "    acertadas = Accuracy(testSet, predicciones)\n",
    "    print('Acertadas: {0}%').format(acertadas)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
